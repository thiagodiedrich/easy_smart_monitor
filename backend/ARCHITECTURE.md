# Arquitetura do Backend - Easy Smart Monitor v1.1.0

## üìê Vis√£o Geral

Este documento descreve a arquitetura do backend da API Easy Smart Monitor v1.1.0, implementando o **Claim Check Pattern** e **TimescaleDB Continuous Aggregates** para processar payloads grandes de telemetria de forma escal√°vel.

## üèóÔ∏è Arquitetura de Alto N√≠vel

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Cliente   ‚îÇ (Home Assistant Integration)
‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ HTTPS
       ‚îÇ JWT Bearer Token
       ‚îÇ Payload: 1-10MB (GZIP comprimido)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   API Gateway (Node.js + Fastify)   ‚îÇ
‚îÇ  - Recebe requisi√ß√µes HTTP          ‚îÇ
‚îÇ  - Valida√ß√£o r√°pida                  ‚îÇ
‚îÇ  - Autentica√ß√£o JWT                  ‚îÇ
‚îÇ  - Rate Limiting (Redis)             ‚îÇ
‚îÇ  - Salva arquivo em MinIO (streaming)‚îÇ
‚îÇ  - Gera Claim Check                 ‚îÇ
‚îÇ  - Endpoints Analytics (TimescaleDB) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚ñº                 ‚ñº                 ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MinIO     ‚îÇ  ‚îÇ    Kafka    ‚îÇ  ‚îÇ    Redis    ‚îÇ  ‚îÇ TimescaleDB  ‚îÇ
‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ
‚îÇ - Arquivos  ‚îÇ  ‚îÇ - Claim     ‚îÇ  ‚îÇ - Rate      ‚îÇ  ‚îÇ - Dados     ‚îÇ
‚îÇ   1-10MB    ‚îÇ  ‚îÇ   Checks    ‚îÇ  ‚îÇ   Limit     ‚îÇ  ‚îÇ   brutos    ‚îÇ
‚îÇ - GZIP      ‚îÇ  ‚îÇ   ~1KB      ‚îÇ  ‚îÇ - Cache     ‚îÇ  ‚îÇ - Continuous‚îÇ
‚îÇ - Reten√ß√£o  ‚îÇ  ‚îÇ - 100K+     ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ   Aggregates‚îÇ
‚îÇ   7 dias    ‚îÇ  ‚îÇ   msg/s     ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ - Queries   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ   otimizadas‚îÇ
       ‚îÇ                 ‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                 ‚ñº                                 ‚îÇ
       ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
       ‚îÇ         ‚îÇ   Python Workers (M√∫ltiplos)        ‚îÇ  ‚îÇ
       ‚îÇ         ‚îÇ  - Consomem Claim Check do Kafka     ‚îÇ  ‚îÇ
       ‚îÇ         ‚îÇ  - Baixam arquivo do MinIO          ‚îÇ  ‚îÇ
       ‚îÇ         ‚îÇ  - Processam em lotes                ‚îÇ  ‚îÇ
       ‚îÇ         ‚îÇ  - Criam/atualizam equipamentos      ‚îÇ  ‚îÇ
       ‚îÇ         ‚îÇ  - Bulk inserts no TimescaleDB       ‚îÇ  ‚îÇ
       ‚îÇ         ‚îÇ  - Removem arquivo (opcional)        ‚îÇ  ‚îÇ
       ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
       ‚îÇ                ‚îÇ                                    ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   TimescaleDB    ‚îÇ
              ‚îÇ  - Hypertable    ‚îÇ
              ‚îÇ  - Continuous    ‚îÇ
              ‚îÇ    Aggregates    ‚îÇ
              ‚îÇ  - Queries       ‚îÇ
              ‚îÇ    otimizadas    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üéØ Claim Check Pattern

### Conceito

O **Claim Check Pattern** resolve o problema de payloads grandes no Kafka:

1. **Problema**: Kafka n√£o √© eficiente com mensagens grandes (> 1MB)
2. **Solu√ß√£o**: Salvar payload em storage, enviar apenas refer√™ncia no Kafka
3. **Benef√≠cio**: Kafka processa milh√µes de mensagens pequenas (~1KB)

### Fluxo Detalhado

#### 1. Recebimento (Gateway)

```javascript
// Cliente envia payload grande (1-10MB)
POST /api/v1/telemetry/bulk
[ { equip_uuid: "...", sensor: [...] } ]

// Gateway:
// 1. Valida (JWT, schema, rate limit)
// 2. Salva arquivo em MinIO (streaming, comprimido GZIP)
// 3. Gera Claim Check:
{
  claim_check: "telemetry/2024-01-15-10-30-00/uuid.json.gz",
  storage_type: "minio",
  file_size: 1500000,
  original_size: 5000000
}
// 4. Envia Claim Check para Kafka (~1KB)
// 5. Responde 202 Accepted (imediato)
```

#### 2. Processamento (Worker)

```python
# Worker consome Claim Check do Kafka
claim_check = {
  "claim_check": "telemetry/2024-01-15-10-30-00/uuid.json.gz",
  "file_size": 1500000
}

# 1. Baixa arquivo do MinIO
data = await storage_client.download_file(claim_check['claim_check'])

# 2. Descomprime GZIP
# 3. Processa telemetria
result = await processor.process_bulk(user_id, data, db)

# 4. Insere no TimescaleDB (bulk)
# 5. Remove arquivo (opcional)
```

## üìä TimescaleDB Continuous Aggregates

### Conceito

**Continuous Aggregates** pr√©-calculam agrega√ß√µes automaticamente:

1. **Problema**: Queries anal√≠ticas em bilh√µes de linhas s√£o lentas
2. **Solu√ß√£o**: Agrega√ß√µes pr√©-calculadas (hor√°ria/di√°ria)
3. **Benef√≠cio**: Queries 100-2000x mais r√°pidas (milissegundos)

### Agrega√ß√µes Implementadas

#### Agrega√ß√£o Hor√°ria (`telemetry_hourly`)

```sql
CREATE MATERIALIZED VIEW telemetry_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', timestamp) AS bucket,
    equipment_id,
    sensor_id,
    AVG(value) AS avg_value,
    MAX(value) AS max_value,
    MIN(value) AS min_value,
    COUNT(*) AS sample_count,
    STDDEV(value) AS stddev_value,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY value) AS median_value,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY value) AS p95_value,
    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY value) AS p99_value
FROM telemetry_data
GROUP BY bucket, equipment_id, sensor_id;
```

**Uso:** Dashboards, an√°lises recentes (√∫ltimas 24h-7d)

#### Agrega√ß√£o Di√°ria (`telemetry_daily`)

```sql
CREATE MATERIALIZED VIEW telemetry_daily
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', timestamp) AS bucket,
    equipment_id,
    sensor_id,
    AVG(value) AS avg_value,
    MAX(value) AS max_value,
    MIN(value) AS min_value,
    COUNT(*) AS sample_count,
    STDDEV(value) AS stddev_value,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY value) AS median_value,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY value) AS p95_value,
    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY value) AS p99_value
FROM telemetry_data
GROUP BY bucket, equipment_id, sensor_id;
```

**Uso:** An√°lises hist√≥ricas, tend√™ncias (30d-1y)

### Pol√≠ticas Autom√°ticas

#### Refresh Autom√°tico

- **Hor√°ria**: Atualiza a cada 30 minutos
- **Di√°ria**: Atualiza a cada 2 horas
- **Real-Time**: Combina dados materializados com dados brutos recentes

#### Reten√ß√£o de Dados

- **Dados brutos**: 30 dias (depois removidos automaticamente)
- **Agregados**: Mantidos indefinidamente (leves, valiosos)

## üéØ Componentes Principais

### 1. API Gateway (Node.js + Fastify)

**Responsabilidades:**
- Receber requisi√ß√µes HTTP
- Validar autentica√ß√£o JWT
- Rate limiting (Redis)
- Salvar arquivo em MinIO (streaming)
- Gerar Claim Check
- Enviar Claim Check para Kafka
- Consultas Analytics (TimescaleDB)
- Responder imediatamente ao cliente

**Tecnologias:**
- Fastify (framework web)
- @fastify/jwt (autentica√ß√£o)
- minio (Object Storage client)
- kafkajs (produtor Kafka)
- ioredis (rate limiting)
- pg (PostgreSQL client para analytics)

**Performance:**
- Lat√™ncia: 10-50ms (salva local, n√£o bloqueia)
- Throughput: 10,000+ req/s
- Streaming: N√£o consome mem√≥ria excessiva

### 2. Object Storage (MinIO)

**Configura√ß√£o:**
- **Bucket**: `telemetry-raw`
- **Estrutura**: `telemetry/YYYY-MM-DD-HH-MM-SS/uuid.json.gz`
- **Compress√£o**: GZIP (70-85% de redu√ß√£o)
- **Reten√ß√£o**: 7 dias (configur√°vel)
- **Acesso**: API (porta 9000) e Console (porta 9001)

**Benef√≠cios:**
- Armazena payloads grandes sem impacto no Kafka
- Permite reprocessamento
- Serve como Data Lake
- Custo baixo (storage local)

### 3. Message Broker (Apache Kafka)

**Configura√ß√£o:**
- **T√≥pico**: `telemetry.raw`
- **Parti√ß√µes**: 3 (para paralelismo)
- **Tamanho Mensagem**: ~1KB (apenas Claim Check)
- **Throughput**: 100,000+ msg/s
- **Reten√ß√£o**: 7 dias

**Benef√≠cios:**
- Processa milh√µes de mensagens pequenas
- N√£o engasga com payloads grandes
- Distribui carga entre workers
- Retry autom√°tico

### 4. Workers Python

**Responsabilidades:**
- Consumir Claim Check do Kafka
- Baixar arquivo do MinIO
- Descomprimir GZIP
- Processar telemetria
- Inserir no TimescaleDB (bulk)
- Remover arquivo ap√≥s processamento

**Tecnologias:**
- kafka-python (consumidor)
- minio (cliente MinIO)
- orjson (JSON r√°pido)
- SQLAlchemy (async)
- asyncpg (PostgreSQL)

**Escalabilidade:**
- M√∫ltiplos workers (2+ r√©plicas)
- Processamento em lotes
- Bulk inserts otimizados

### 5. Banco de Dados TimescaleDB

**Estrutura:**
- `users`: Autentica√ß√£o
- `equipments`: Dispositivos
- `sensors`: Sensores
- `telemetry_data`: Dados de telemetria (hypertable)
- `telemetry_hourly`: Agrega√ß√£o hor√°ria (continuous aggregate)
- `telemetry_daily`: Agrega√ß√£o di√°ria (continuous aggregate)

**Otimiza√ß√µes:**
- Hypertable com chunks de 1 dia
- √çndices compostos
- Bulk inserts
- Connection pooling
- Continuous Aggregates autom√°ticos

## üîÑ Fluxo de Dados Completo

### Cen√°rio: Cliente envia 50 dispositivos (100MB)

1. **Cliente ‚Üí Gateway** (HTTP POST, 100MB GZIP = ~30MB)
2. **Gateway valida** (JWT, schema, rate limit) - 5ms
3. **Gateway salva em MinIO** (streaming, comprimido) - 200ms
4. **Gateway gera Claim Check** - 1ms
5. **Gateway ‚Üí Kafka** (Claim Check ~1KB) - 10ms
6. **Gateway ‚Üí Cliente** (202 Accepted) - **Total: ~216ms** ‚úÖ

7. **Kafka ‚Üí Worker** (Claim Check) - 5ms
8. **Worker baixa do MinIO** - 150ms
9. **Worker descomprime** - 50ms
10. **Worker processa** - 500ms
11. **Worker insere no DB** - 300ms
12. **Continuous Aggregates atualizam** - Autom√°tico (background)
13. **Worker remove arquivo** - 10ms
14. **Worker commita offset** - 5ms

**Total processamento**: ~1 segundo (ass√≠ncrono, n√£o bloqueia cliente)

### Consulta Analytics (Dashboard)

1. **Cliente ‚Üí Gateway** (GET /analytics/equipment/:uuid/history)
2. **Gateway valida** (JWT) - 5ms
3. **Gateway consulta TimescaleDB** (Continuous Aggregate) - 10-50ms
4. **Gateway ‚Üí Cliente** (JSON response) - **Total: 15-55ms** ‚úÖ

**Sem Continuous Aggregates**: 5-20 segundos ‚ùå
**Com Continuous Aggregates**: 10-50 milissegundos ‚úÖ

## üìä Performance

### Benchmarks Estimados

- **Throughput Gateway**: 10,000+ requisi√ß√µes/segundo
- **Lat√™ncia Gateway**: 10-50ms (p95)
- **Throughput Kafka**: 100,000+ mensagens/segundo
- **Throughput Workers**: 1,000-2,000 arquivos/segundo por worker
- **Tamanho Kafka**: ~1KB por mensagem (vs 1-10MB antes)
- **Queries Analytics**: 10-50ms (vs 5-20s antes)

### Otimiza√ß√µes

- **Streaming**: Gateway n√£o carrega payload completo na mem√≥ria
- **Compress√£o**: GZIP reduz 70-85% do tamanho
- **Bulk Inserts**: Lotes de 1000 registros
- **Processamento em Lotes**: 100 mensagens por vez
- **Connection Pooling**: Pool de 20 conex√µes
- **Continuous Aggregates**: Pr√©-c√°lculo autom√°tico

## üîê Seguran√ßa

### Implementado

- ‚úÖ JWT tokens com expira√ß√£o curta
- ‚úÖ Rate limiting por IP e usu√°rio
- ‚úÖ Valida√ß√£o rigorosa de dados
- ‚úÖ HTTPS obrigat√≥rio em produ√ß√£o
- ‚úÖ Sanitiza√ß√£o de inputs
- ‚úÖ Isolamento de storage
- ‚úÖ Todas as regras de neg√≥cio centralizadas na API

### Boas Pr√°ticas

- Tokens JWT com expira√ß√£o de 15 minutos
- Refresh tokens com 7 dias
- Rate limiting configur√°vel
- Logs estruturados para auditoria
- Arquivos com metadados (user_id, request_id)

## üìà Escalabilidade

### Horizontal Scaling

- **Gateway**: M√∫ltiplas inst√¢ncias atr√°s de load balancer
- **Workers**: M√∫ltiplos workers (escalam facilmente)
- **Kafka**: Cluster mode para alta disponibilidade
- **MinIO**: Cluster mode para alta disponibilidade
- **Database**: Read replicas para consultas

### Vertical Scaling

- Aumentar recursos de workers para processamento pesado
- Aumentar parti√ß√µes do Kafka para mais paralelismo
- Aumentar pool de conex√µes do banco

## üöÄ Deploy

### Docker Compose

Servi√ßos:
- `gateway`: API Gateway Node.js
- `worker`: Workers Python (2+ r√©plicas)
- `minio`: Object Storage
- `kafka`: Message broker
- `zookeeper`: Coordena√ß√£o Kafka
- `postgres`: TimescaleDB
- `redis`: Cache e rate limiting

### Vari√°veis de Ambiente

Todas as configura√ß√µes via `.env`:
- URLs de conex√£o
- Chaves secretas
- Limites e timeouts
- Pol√≠ticas de reten√ß√£o

## üìù Logging e Monitoramento

### Logging Estruturado

- **Formato**: JSON (produ√ß√£o) ou console (desenvolvimento)
- **N√≠veis**: DEBUG, INFO, WARNING, ERROR
- **Contexto**: Inclui user_id, request_id, claim_check, etc.

### Health Checks

- `/api/v1/health`: Health check b√°sico
- `/api/v1/health/detailed`: Verifica depend√™ncias (Kafka, MinIO, TimescaleDB)

### M√©tricas

- **Kafka**: Lag do consumidor, throughput
- **MinIO**: Espa√ßo usado, objetos por bucket
- **Workers**: Arquivos processados, erros
- **TimescaleDB**: Tamanho de chunks, status de continuous aggregates

## üìä Volume de Dados

### Estimativas

- **Exemplo**: 1 dispositivo, 4 sensores = 4MB a cada 8 horas
- **Proje√ß√£o**: 1000 dispositivos = ~500MB/hora = ~12GB/dia
- **Solu√ß√£o**: Claim Check Pattern + bulk inserts + limpeza autom√°tica

### Reten√ß√£o

- **Kafka**: 7 dias (apenas Claim Checks)
- **MinIO**: 7 dias (arquivos completos)
- **TimescaleDB Dados Brutos**: 30 dias (configur√°vel)
- **TimescaleDB Agregados**: Indefinidamente
- **Limpeza**: Autom√°tica (pol√≠ticas configuradas)

## üõ†Ô∏è Tecnologias

- **Node.js**: Runtime para gateway
- **Fastify**: Framework web ass√≠ncrono
- **MinIO**: Object Storage (S3-compatible)
- **Kafka**: Message broker
- **Python**: Workers de processamento
- **TimescaleDB**: Banco de dados time-series
- **Redis**: Cache e rate limiting
- **SQLAlchemy**: ORM
- **Docker**: Containeriza√ß√£o

## üìö Pr√≥ximos Passos

1. **Autentica√ß√£o Real**: Integrar gateway com banco de dados
2. **M√©tricas Prometheus**: Exportar m√©tricas
3. **Tracing**: OpenTelemetry para observabilidade
4. **Dead Letter Queue**: Para mensagens com erro persistente
5. **WebSockets**: Para notifica√ß√µes em tempo real
6. **Particionamento**: Tabela de telemetria particionada por m√™s
7. **MinIO Cluster**: Para alta disponibilidade

---

**Arquitetura v1.1.0 escal√°vel e robusta para milh√µes de pontos de telemetria!** üöÄ
