services:
  # API Gateway (Node.js + Fastify)
  gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile
    container_name: easysmart_gateway
    ports:
      - "8000:8000"
    environment:
      - NODE_ENV=production
      - HOST=0.0.0.0
      - PORT=8000
      - SECRET_KEY=${SECRET_KEY:-change-me-in-production-min-32-chars}
      - ACCESS_TOKEN_EXPIRE_MINUTES=15
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_TOPIC=telemetry.raw
      - KAFKA_CLIENT_ID=easysmart-gateway
      - REDIS_URL=redis://redis:6379/0
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - MINIO_BUCKET=telemetry-raw
      - STORAGE_TYPE=minio
      - DATABASE_URL=postgresql://${POSTGRES_USER:-easysmart}:${POSTGRES_PASSWORD:-easysmart_password}@postgres:5432/${POSTGRES_DB:-easysmart_db}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-easysmart}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-easysmart_password}
      - POSTGRES_DB=${POSTGRES_DB:-easysmart_db}
      - RATE_LIMIT_PER_MINUTE=1000
      - MAX_BULK_SIZE=10000
      - CORS_ORIGINS=http://localhost:3000,http://localhost:8080
      - LOG_LEVEL=info
      - VALID_USERS=${VALID_USERS:-{"admin":"admin123"}}
      - KAFKAJS_NO_PARTITIONER_WARNING=1
    volumes:
      - ./gateway/src:/app/src
    depends_on:
      kafka:
        condition: service_started
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - easysmart_network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Python Workers (Processam telemetria do Kafka)
  # Sem container_name: com deploy.replicas cada réplica recebe nome único (ex.: backend-worker-1, backend-worker-2).
  worker:
    build:
      context: ./workers-python
      dockerfile: Dockerfile
    volumes:
      - ./workers-python/app:/app/app
      - ./workers-python/run_migrations.py:/app/run_migrations.py
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-easysmart}:${POSTGRES_PASSWORD:-easysmart_password}@postgres:5432/${POSTGRES_DB:-easysmart_db}
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_TOPIC=telemetry.raw
      - KAFKA_GROUP_ID=telemetry-workers
      - KAFKA_BATCH_SIZE=100
      - KAFKA_AUTO_COMMIT=false
      - BULK_INSERT_BATCH_SIZE=1000
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
      - DEBUG=false
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy
      gateway:
        condition: service_started
    restart: unless-stopped
    networks:
      - easysmart_network
    deploy:
      replicas: 2  # Múltiplos workers para paralelismo

  # Alert Worker (Alertas + Webhooks)
  alert-worker:
    build:
      context: ./workers-python
      dockerfile: Dockerfile
    volumes:
      - ./workers-python/app:/app/app
    command: ["python", "-m", "app.workers.alert_worker"]
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-easysmart}:${POSTGRES_PASSWORD:-easysmart_password}@postgres:5432/${POSTGRES_DB:-easysmart_db}
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
      - ALERTS_ENABLED=${ALERTS_ENABLED:-false}
      - WEBHOOKS_ENABLED=${WEBHOOKS_ENABLED:-false}
      - ALERT_POLL_SECONDS=${ALERT_POLL_SECONDS:-60}
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - easysmart_network

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: easysmart_kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # Um único listener: bind em 0.0.0.0 para outros containers; anunciar kafka:9092 na rede Docker
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168  # 7 dias
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1GB
    volumes:
      - kafka_data:/var/lib/kafka/data
    depends_on:
      zookeeper:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - easysmart_network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 60s

  # Zookeeper (Requerido pelo Kafka)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: easysmart_zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    restart: unless-stopped
    networks:
      - easysmart_network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 30s
      timeout: 10s
      retries: 5

  # TimescaleDB (PostgreSQL com extensão TimescaleDB)
  postgres:
    image: timescale/timescaledb:latest-pg15
    container_name: easysmart_postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-easysmart}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-easysmart_password}
      - POSTGRES_DB=${POSTGRES_DB:-easysmart_db}
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    networks:
      - easysmart_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-easysmart}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis
  redis:
    image: redis:7-alpine
    container_name: easysmart_redis
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped
    networks:
      - easysmart_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MinIO (Object Storage para Claim Check Pattern)
  minio:
    image: minio/minio:latest
    container_name: easysmart_minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Console
    restart: unless-stopped
    networks:
      - easysmart_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
  redis_data:
  kafka_data:
  zookeeper_data:
  minio_data:

networks:
  easysmart_network:
    driver: bridge
