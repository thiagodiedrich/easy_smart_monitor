import aiohttp
import asyncio
import logging
import os
import json
from datetime import datetime
from typing import List, Dict, Any, Optional

# Importações oficiais do Core para persistência atômica segura
from homeassistant.helpers.json import save_json
from homeassistant.util.json import load_json
from homeassistant.core import HomeAssistant

from .const import (
    DOMAIN,
    STORAGE_FILE,
    TEST_MODE,
    MAX_RETRIES,
    RETRY_DELAY,
    HEADERS
)

_LOGGER = logging.getLogger(__name__)

class EasySmartClient:
    """
    Cliente API exaustivo com persistência nativa HA,
    gestão de concorrência e lógica de re-tentativa (Retry).
    """

    def __init__(self, host: str, username: str, password: str, session: aiohttp.ClientSession, hass: HomeAssistant):
        """Inicializa o cliente com caminhos de armazenamento protegidos pelo Core do HA."""
        self.host = host.rstrip("/")
        self.username = username
        self.password = password
        self.session = session
        self.hass = hass
        self.queue: List[Dict[str, Any]] = []
        self.token: Optional[str] = None

        # Define o caminho absoluto dentro de /config/.storage/
        self.storage_path = hass.config.path(".storage", STORAGE_FILE)

        # Lock de concorrência para evitar que múltiplos envios ocorram simultaneamente
        self._lock = asyncio.Lock()

        _LOGGER.debug("Cliente Easy Smart inicializado. Caminho de armazenamento: %s", self.storage_path)

    async def authenticate(self) -> bool:
        """Realiza a autenticação e obtém o Bearer Token para as requisições."""
        if TEST_MODE:
            _LOGGER.info("MODO TESTE: Simulando sucesso na autenticação.")
            self.token = "token_teste_v10_estavel"
            return True

        url = f"{self.host}/auth/login"
        payload = {
            "username": self.username,
            "password": self.password
        }

        _LOGGER.debug("Enviando requisição de login para: %s", url)
        try:
            async with self.session.post(url, json=payload, timeout=15) as response:
                if response.status == 200:
                    data = await response.json()
                    self.token = data.get("access_token")
                    _LOGGER.info("Autenticação na API Easy Smart realizada com sucesso.")
                    return True

                _LOGGER.error(
                    "Falha na autenticação. Status: %s. Verifique se as credenciais estão corretas.",
                    response.status
                )
        except asyncio.TimeoutError:
            _LOGGER.error("Timeout durante a tentativa de autenticação. Servidor API lento ou inacessível.")
        except aiohttp.ClientError as e:
            _LOGGER.error("Erro de conexão durante a autenticação: %s", e)
        except Exception as e:
            _LOGGER.error("Erro inesperado no processo de login: %s", e)

        return False

    def add_to_queue(self, data: Dict[str, Any]):
        """Adiciona dados à fila de telemetria e garante a persistência física imediata."""
        if not isinstance(data, dict):
            _LOGGER.error("Erro de formato: Tentativa de enfileirar dado que não é um dicionário: %s", data)
            return

        # Garante a integridade do timestamp para o histórico da API
        if "timestamp" not in data:
            data["timestamp"] = datetime.now().isoformat()

        self.queue.append(data)
        _LOGGER.debug("Evento de telemetria enfileirado localmente. Itens na fila: %s", len(self.queue))

        # Agenda a gravação para o disco de forma assíncrona (Thread-safe)
        self.hass.add_job(self._save_queue_to_disk)

    async def sync_queue(self) -> bool:
        """
        Sincroniza a fila acumulada com o servidor remoto.
        Implementa Retry, Renovação de Token automático e tratamento de erros de rede.
        """
        if not self.queue:
            _LOGGER.debug("Sincronização ignorada: Fila vazia.")
            return True

        # O Lock garante que se um ciclo de rede demorar, o próximo não atropele o atual
        async with self._lock:
            if TEST_MODE:
                _LOGGER.info("MODO TESTE: Simulação de envio bulk de %s itens concluída.", len(self.queue))
                self.queue.clear()
                self._save_queue_to_disk()
                return True

            # Se não temos token, tentamos autenticar antes de prosseguir
            if not self.token and not await self.authenticate():
                _LOGGER.warning("Sincronização cancelada: Falha crítica na autenticação.")
                return False

            attempts = 0
            while attempts < MAX_RETRIES:
                try:
                    url = f"{self.host}/api/telemetria/bulk"
                    auth_headers = {
                        **HEADERS,
                        "Authorization": f"Bearer {self.token}"
                    }

                    _LOGGER.debug("Tentativa de envio bulk %s/%s para %s", attempts + 1, MAX_RETRIES, url)

                    async with self.session.post(
                        url,
                        json=self.queue,
                        headers=auth_headers,
                        timeout=25
                    ) as response:

                        if response.status in [200, 201]:
                            _LOGGER.info("Sucesso! %s eventos de telemetria enviados para a API central.", len(self.queue))
                            self.queue.clear()
                            self._save_queue_to_disk()
                            return True

                        if response.status == 401:
                            _LOGGER.warning("Token expirado (401). Tentando renovação de credenciais...")
                            if await self.authenticate():
                                attempts += 1
                                continue # Tenta o envio novamente com o novo token

                        _LOGGER.warning(
                            "Resposta negativa da API (Status %s). Tentativa %s/%s",
                            response.status, attempts + 1, MAX_RETRIES
                        )

                except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                    _LOGGER.warning(
                        "Falha de rede na comunicação com a API: %s. Aguardando %ss para re-tentativa...",
                        e, RETRY_DELAY
                    )

                attempts += 1
                if attempts < MAX_RETRIES:
                    await asyncio.sleep(RETRY_DELAY)

            _LOGGER.error("Falha persistente na sincronização após %s tentativas. Dados mantidos para o próximo ciclo.", MAX_RETRIES)
            return False

    def _save_queue_to_disk(self):
        """
        Gravação robusta da fila usando helpers oficiais do HA.
        Resolve problemas de permissão e latência de I/O em containers.
        """
        try:
            storage_dir = os.path.dirname(self.storage_path)
            if not os.path.exists(storage_dir):
                os.makedirs(storage_dir, exist_ok=True)

            # save_json do HA faz a escrita atômica internamente (.tmp -> rename)
            save_json(self.storage_path, self.queue)
            _LOGGER.debug("Estado da fila persistido com sucesso no diretório .storage.")
        except Exception as e:
            _LOGGER.error("Erro crítico ao salvar dados da fila no disco: %s", e)

    async def load_queue_from_disk(self):
        """Carrega a fila persistida durante o boot da integração."""
        if not os.path.exists(self.storage_path):
            _LOGGER.debug("Arquivo de fila pendente não encontrado. Iniciando nova fila.")
            return

        try:
            # Carrega usando o utilitário nativo do HA em uma thread separada
            data = await self.hass.async_add_executor_job(
                load_json, self.storage_path
            )

            if isinstance(data, list):
                self.queue = data
                _LOGGER.info("Persistência carregada: %s eventos restaurados para a fila.", len(self.queue))
            else:
                _LOGGER.warning("Arquivo de fila encontrado com formato inválido. Iniciando fila limpa.")
        except Exception as e:
            _LOGGER.error("Falha ao carregar fila do armazenamento local: %s", e)
            # Em caso de corrupção física do JSON, gera backup para não travar o sistema
            if os.path.exists(self.storage_path):
                backup_name = f"{self.storage_path}.corrupt_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                os.rename(self.storage_path, backup_name)
                _LOGGER.warning("O arquivo corrompido foi movido para: %s", backup_name)

    def get_diagnostics(self) -> Dict[str, Any]:
        """Extrai métricas de saúde interna para os sensores de diagnóstico."""
        return {
            "queue_size": len(self.queue),
            "is_authenticated": self.token is not None,
            "api_host": self.host,
            "test_mode": TEST_MODE,
            "storage_location": self.storage_path
        }